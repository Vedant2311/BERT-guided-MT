{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9761229a-0efc-406c-8179-701d97c80c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import sentencepiece as spm\n",
    "\n",
    "class LanguageDataset(Dataset):                                  \n",
    "\n",
    "    def __init__(self, tokenizer, file, max_length):\n",
    "        self.tokens = tokenizer(file)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "              \n",
    "    # input_ids attention_mask encoder_mask decoder_mask \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9f57006-4b54-4705-8afb-e42c30f12df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file -> token\n",
    "def tokenizer_example(file, model_prefix='nepali_spm', vocab_size=504, character_coverage=1.0, model_type='bpe'):\n",
    "    spm.SentencePieceTrainer.train(\n",
    "            f'--input={file} --model_prefix={model_prefix} --vocab_size={vocab_size} \\\n",
    "            --character_coverage={character_coverage} --model_type={model_type}'\n",
    "        )\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.load(f'{model_prefix}.model')\n",
    "    with open(file) as f:\n",
    "        text = f.read()\n",
    "    tokens = sp.encode_as_pieces(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e35b54cf-4ae1-4050-9c10-49fbdb76e516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁प्याच',\n",
       " '▁गरिने',\n",
       " '▁फाइल',\n",
       " '/',\n",
       " 'डाइरेक्टरी',\n",
       " '▁image',\n",
       " '-',\n",
       " 'action',\n",
       " '▁प्रशारण',\n",
       " '▁ठेगाना',\n",
       " ':',\n",
       " 'Subnet',\n",
       " '▁Mask',\n",
       " '▁पाँच',\n",
       " '▁वा',\n",
       " '▁बढी',\n",
       " '▁प्रकार',\n",
       " '▁प्राप्त',\n",
       " '▁गर्नका',\n",
       " '▁लागि',\n",
       " '▁कुञ्जी',\n",
       " '▁वा',\n",
       " '▁कुञ्जीहरू',\n",
       " '▁निर्दिष्ट',\n",
       " '▁गर्नु',\n",
       " '▁पर्दछ',\n",
       " '▁यसमा',\n",
       " '▁सञ्चालन',\n",
       " '▁गर्न',\n",
       " '▁पीडीए',\n",
       " '▁निर्दिष्ट',\n",
       " '▁गर्नुहोस्',\n",
       " '▁(',\n",
       " 'MyPDA',\n",
       " '▁मा',\n",
       " '▁पूर्वनिर्धारित',\n",
       " '▁हुन्छ',\n",
       " ')',\n",
       " '▁जगेडा',\n",
       " '▁पहिचायक',\n",
       " '▁Description',\n",
       " '▁Query',\n",
       " '▁फोल्डर',\n",
       " '▁सिर्जना',\n",
       " '▁गर्न',\n",
       " '▁सकेन',\n",
       " '▁।',\n",
       " '▁लुयन्डा',\n",
       " 'africa',\n",
       " '.',\n",
       " '▁kgm',\n",
       " '▁अघिल्लो',\n",
       " '▁चेक',\n",
       " '▁बाकसमा',\n",
       " '▁जान्छ',\n",
       " '▁।']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_example('/Users/ryanmarr/Downloads/train_ne_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "267ea3bc-242c-4eda-bfb1-9a0c236296f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langdset = LanguageDataset(tokenizer=tokenizer_example,\n",
    "                           file='/Users/ryanmarr/Downloads/train_ne_small.txt', \n",
    "                           max_length=10\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "705b9a54-e279-49be-86d7-4bbfa91ac998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁image'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langdset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44f53c75-08f4-4a22-924d-2bbb32432a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attn mask input target for batch size\n",
    "batch_size = 10\n",
    "shuffle = True\n",
    "data_loader = DataLoader(dataset=langdset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d60e21-55d9-4c5c-a6e3-b1d4af31fa47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
