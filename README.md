# BERT-guided-MT
Utilizing expert pre-trained systems like BERT to improve the performance of low resource NMT
TODO: Improve the README as we go along the project

## Data for test/train
- FLORES evaluation dataset for Ne-En (test + dev)
https://aclanthology.org/D19-1632/

- Training data for Ne-En
1) Bible Corpus (62K sentences, 1.5M tokens) https://link.springer.com/article/10.1007/s10579-014-9287-y
2) GNOME/KDE/Ubuntu (495K sentences, 2M tokens) https://opus.nlpl.eu

## Link to over-leaf
https://www.overleaf.com/project/654eada2c12fd97579569538
